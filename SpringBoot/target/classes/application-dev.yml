server:
  port: 8080

spring:
  kafka:
    bootstrap-servers: 127.0.0.1:9092
    producer:
    #      retries: 1
    #      batch-size: 16384
    #      buffer-memory: 33554432
      key-serializer: org.apache.kafka.common.serialization.StringDeserializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    consumer:
      group-id: test-consumer-group
      enable-auto-commit: true
      auto-commit-interval: 100
      #      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer

  datasource:
    name: root
    password: 123456
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://localhost:3306/db2?useUnicode=true&characterEncoding=utf-8&useSSL=false&serverTimezone=UTC

  application:
    name: dsd

    redis:
      database: 0  # Redis数据库索引（默认为0）
      host: localhost # Redis服务器地址
      port: 6379  # Redis服务器连接端口
      password: # Redis服务器连接密码（默认为空）
      lettuce:
         pool:
          max-active: 8 # 连接池最大连接数（使用负值表示没有限制）
          max-wait: -1 # 连接池最大阻塞等待时间（使用负值表示没有限制）
          max-idle: 8 # 连接池中的最大空闲连接
          min-idle: 0 # 连接池中的最小空闲连接
      timeout: 10000  # 连接超时时间（毫秒）

    cache:
      type: redis  # 一般来说是不用配置的，Spring Cache 会根据依赖的包自行装配

    data:
      mongodb:
        uri: mongodb://localhost/test
        username:
        password:


mybatis:
  mapper-locations: classpath:mapper/*.xml
  type-aliases-package: com.example.demo.entity



# 访问URL：
# http://localhost:8080/sysc_log
# http://localhost:8080/




